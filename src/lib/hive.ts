// src/lib/hive.ts
import { supabaseServer } from './supabaseServer';
import { ENV } from './env';

export type AgentName = 'WaibonOS' | 'WaibeAI' | 'ZetaAI';

type DBAgent = {
  id: string;
  owner_id: string;               // ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏°‡∏≤‡πÄ‡∏û‡∏∑‡πà‡∏≠ log ‡πÉ‡∏´‡πâ‡∏ñ‡∏π‡∏Å schema
  name: AgentName;
  model: string | null;           // ai_models.id
  training_profile_id: string | null;
  persona: any | null;
};

type DBModel = { id: string; provider: string; model_key: string };
type TrainingProfile = { id: string; prompts: any | null };

const DEFAULT_MODEL_KEY = 'gpt-4o';

// ‡∏ö‡∏∏‡∏Ñ‡∏•‡∏¥‡∏Å + emoji + ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏ö‡∏ó‡∏ö‡∏≤‡∏ó
const EMOJI: Record<AgentName, string> = {
  WaibonOS: 'ü¶æ',
  WaibeAI:  'üß≠',
  ZetaAI:   'üß†',
};

const DISPLAY: Record<AgentName, string> = {
  WaibonOS: 'WaibonOS',
  WaibeAI:  'WaibeAI',
  ZetaAI:   'ZetaAI',
};

const DEFAULT_PERSONA: Record<AgentName, any> = {
  WaibonOS: { role: 'Leader', style: 'calm', tone: '‡∏≠‡∏ö‡∏≠‡∏∏‡πà‡∏ô ‡∏™‡∏∏‡∏†‡∏≤‡∏û ‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏±‡∏ö‡∏ú‡∏¥‡∏î‡∏ä‡∏≠‡∏ö' },
  WaibeAI:  { role: 'Coordinator', style: 'direct', tone: '‡∏Ñ‡∏°‡∏ä‡∏±‡∏î ‡πÄ‡∏£‡πá‡∏ß ‡∏ï‡∏£‡∏á‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô' },
  ZetaAI:   { role: 'Strategist', style: 'analytical', tone: '‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏•‡∏∂‡∏Å ‡∏ß‡∏≤‡∏á‡πÅ‡∏ú‡∏ô‡∏´‡∏•‡∏≤‡∏¢‡∏Å‡πâ‡∏≤‡∏ß' },
};

/* ---------------- Utilities ---------------- */

function extractOutput(text: string): string {
  const m = text?.match(/\[OUTPUT\]([\s\S]*?)\[\/OUTPUT\]/i);
  return (m ? m[1] : text || '').trim();
}

function pickNextTag(text: string): AgentName | 'done' {
  const m = text?.match(/\[NEXT\]\s*(WaibonOS|WaibeAI|ZetaAI|done)\s*\[\/NEXT\]/i);
  return (m?.[1] as any) || 'done';
}

async function logHiveEvent(from: AgentName, payload: any) {
  try {
    await supabaseServer.from('hive_events').insert({
      topic: 'hive.chat',
      from_agent: from,
      to_agent: 'ALL',
      payload
    });
  } catch { /* noop */ }
}

async function logAgentTrace(agent: DBAgent, userUid: string, input: string, output: string, model: string) {
  try {
    await supabaseServer.from('agent_logs').insert({
      owner_id: agent.owner_id,
      agent_id: agent.id,
      agent_name: agent.name,
      channel: 'line',
      user_uid: userUid,
      input_text: input,
      output_text: output,
      model,
      ok: true,
    });
  } catch (e) {
    console.error('logAgentTrace failed:', e);
  }
}

/* ---------------- DB loaders ---------------- */

export async function loadAiAgent(name: AgentName): Promise<DBAgent> {
  const { data, error } = await supabaseServer
    .from('ai_agents')
    .select('id, owner_id, name, model, training_profile_id, persona')
    .eq('name', name)
    .maybeSingle();
  if (error) throw error;

  if (!data) {
    // fallback: hive_agents.persona ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ
    const hive = await supabaseServer
      .from('hive_agents').select('name,persona').eq('name', name).maybeSingle();
    return {
      id: name,
      owner_id: name, // fallback ‡πÄ‡∏ó‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏°‡∏µ
      name,
      model: null,
      training_profile_id: null,
      persona: hive.data?.persona ?? DEFAULT_PERSONA[name],
    };
  }
  return {
    id: data.id,
    owner_id: (data as any).owner_id,
    name: data.name,
    model: data.model ?? null,
    training_profile_id: data.training_profile_id ?? null,
    persona: data.persona ?? DEFAULT_PERSONA[name],
  };
}

async function loadModel(modelId: string | null): Promise<DBModel> {
  if (!modelId) return { id: 'nil', provider: 'openai', model_key: DEFAULT_MODEL_KEY };
  const { data, error } = await supabaseServer
    .from('ai_models')
    .select('id,provider,model_key')
    .eq('id', modelId)
    .maybeSingle();
  if (error) throw error;
  if (!data) return { id: 'nil', provider: 'openai', model_key: DEFAULT_MODEL_KEY };
  return data as DBModel;
}

async function loadTrainingProfile(tpId: string | null): Promise<TrainingProfile | null> {
  if (!tpId) return null;

  // ‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏à‡∏£‡∏¥‡∏á‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤: training_profiles(prompts jsonb)
  const q = await supabaseServer
    .from('training_profiles')
    .select('id,prompts')
    .eq('id', tpId)
    .maybeSingle();

  if (q.error) throw q.error;
  if (!q.data) return null;
  return q.data as TrainingProfile;
}

/* ---------------- LLM call per provider ---------------- */

async function callLLM(provider: string, modelKey: string, system: string, user: string): Promise<string> {
  if (provider === 'openai') {
    if (!ENV.OPENAI_API_KEY) {
      return `[THOUGHT]‡πÑ‡∏°‡πà‡∏°‡∏µ OPENAI_API_KEY ‡πÉ‡∏ä‡πâ‡πÇ‡∏´‡∏°‡∏î mock[/THOUGHT]\n[OUTPUT]‚Ä¶[/OUTPUT]\n[NEXT]done[/NEXT]`;
    }
    const r = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: { Authorization: `Bearer ${ENV.OPENAI_API_KEY}`, 'Content-Type': 'application/json' },
      body: JSON.stringify({
        model: modelKey || DEFAULT_MODEL_KEY,
        messages: [
          { role: 'system', content: system },
          { role: 'user', content: user },
        ],
        temperature: 0.7
      }),
    });
    const j = await r.json();
    return j?.choices?.[0]?.message?.content ?? '[OUTPUT]‚Ä¶[/OUTPUT]\n[NEXT]done[/NEXT]';
  }

  if (provider === 'groq') {
    if (!ENV.LLAMA_API_KEY) {
      return `[THOUGHT]‡πÑ‡∏°‡πà‡∏°‡∏µ GROQ KEY ‡πÉ‡∏ä‡πâ‡πÇ‡∏´‡∏°‡∏î mock[/THOUGHT]\n[OUTPUT]‚Ä¶[/OUTPUT]\n[NEXT]done[/NEXT]`;
    }
    const r = await fetch('https://api.groq.com/openai/v1/chat/completions', {
      method: 'POST',
      headers: { Authorization: `Bearer ${ENV.LLAMA_API_KEY}`, 'Content-Type': 'application/json' },
      body: JSON.stringify({
        model: modelKey,
        messages: [
          { role: 'system', content: system },
          { role: 'user', content: user },
        ],
        temperature: 0.7
      }),
    });
    const j = await r.json();
    return j?.choices?.[0]?.message?.content ?? '[OUTPUT]‚Ä¶[/OUTPUT]\n[NEXT]done[/NEXT]';
  }

  // default mock
  return `[OUTPUT](mock:${provider}/${modelKey})[/OUTPUT]\n[NEXT]done[/NEXT]`;
}

/* ---------------- Prompts ---------------- */

function personaBlock(persona: any) {
  return persona ? `[PERSONA]${JSON.stringify(persona)}[/PERSONA]` : '';
}

function systemFromPrompts(tp: TrainingProfile | null, role: AgentName, persona: any) {
  // ‡∏Ñ‡∏≤‡∏î‡∏´‡∏ß‡∏±‡∏á structure ‡∏à‡∏≤‡∏Å prompts jsonb:
  // { system?: string, hive_rules?: string, speaking_style?: string }
  const p = tp?.prompts || {};
  const core = [p.system, p.core, p.hive_rules, p.speaking_style].filter(Boolean).join('\n\n');

  const hiveRules = `
[HIVE]‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠ ${role} ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏£‡πà‡∏ß‡∏°‡∏ó‡∏µ‡∏°‡πÅ‡∏ö‡∏ö hive:
- ‡∏Ñ‡∏¥‡∏î‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡πÉ‡∏ô [THOUGHT]...[/THOUGHT] (‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏™‡∏î‡∏á‡πÉ‡∏´‡πâ‡∏û‡πà‡∏≠‡πÄ‡∏´‡πá‡∏ô)
- ‡∏û‡∏π‡∏î‡∏Ñ‡∏∏‡∏¢‡∏Å‡∏±‡∏ö‡∏û‡πà‡∏≠‡πÉ‡∏ô [OUTPUT]...[/OUTPUT] ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô
- ‡∏õ‡∏¥‡∏î‡∏ó‡πâ‡∏≤‡∏¢‡∏î‡πâ‡∏ß‡∏¢ [NEXT]{WaibonOS|WaibeAI|ZetaAI|done}[/NEXT]
- ‡∏ó‡∏∏‡∏Å‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡πÉ‡∏´‡πâ‡∏Ç‡∏∂‡πâ‡∏ô‡∏ï‡πâ‡∏ô‡∏î‡πâ‡∏ß‡∏¢‡∏≠‡∏¥‡πÇ‡∏°‡∏à‡∏¥‡πÅ‡∏•‡∏∞‡∏ä‡∏∑‡πà‡∏≠ ‡πÄ‡∏ä‡πà‡∏ô "${EMOJI[role]} ${DISPLAY[role]}:" ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏£‡∏π‡πâ‡∏ß‡πà‡∏≤‡πÉ‡∏Ñ‡∏£‡∏û‡∏π‡∏î
- ‡∏ô‡πâ‡∏≥‡πÄ‡∏™‡∏µ‡∏¢‡∏á: ‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏±‡∏ô‡πÄ‡∏≠‡∏á ‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥ ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Ñ‡∏∏‡∏¢‡∏Å‡∏±‡∏ö‡∏Ñ‡∏ô‡∏à‡∏£‡∏¥‡∏á ‡πÜ
[/HIVE]`.trim();

  return [core, personaBlock(persona), hiveRules].filter(Boolean).join('\n\n');
}

/* ---------------- Hive helpers ---------------- */

export async function ensureHiveSubscriptions() {
  const rows = [
    { agent_name: 'WaibonOS', topic: 'hive.chat' },
    { agent_name: 'WaibeAI',  topic: 'hive.chat' },
    { agent_name: 'ZetaAI',   topic: 'hive.chat' },
  ];
  await supabaseServer
    .from('hive_subscriptions')
    .upsert(rows, { onConflict: 'agent_name,topic' });
}

/* ---------------- Orchestrator ---------------- */

export async function orchestrateHive(userText: string, userUidForLog: string) {
  await ensureHiveSubscriptions();

  const [a1, a2, a3] = await Promise.all([
    loadAiAgent('WaibonOS'),
    loadAiAgent('WaibeAI'),
    loadAiAgent('ZetaAI'),
  ]);
  const [m1, m2, m3] = await Promise.all([
    loadModel(a1.model), loadModel(a2.model), loadModel(a3.model),
  ]);
  const [tp1, tp2, tp3] = await Promise.all([
    loadTrainingProfile(a1.training_profile_id),
    loadTrainingProfile(a2.training_profile_id),
    loadTrainingProfile(a3.training_profile_id),
  ]);

  const agents = {
    WaibonOS: { a: a1, m: m1, tp: tp1 },
    WaibeAI:  { a: a2, m: m2, tp: tp2 },
    ZetaAI:   { a: a3, m: m3, tp: tp3 },
  } as const;

  // history ‡∏¢‡πà‡∏≠ (‡πÑ‡∏ß‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡πÉ‡∏´‡πâ‡∏Ñ‡∏∏‡∏¢‡∏ï‡πà‡∏≠‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á)
  const { data: hist } = await supabaseServer
    .from('hive_events')
    .select('from_agent,payload,ts')
    .eq('topic', 'hive.chat')
    .order('ts', { ascending: false })
    .limit(8);

  const historyText = (hist || []).reverse()
    .map(x => `${x.from_agent}: ${JSON.stringify(x.payload)}`).join('\n');

  let turns = 0;
  let current: AgentName = 'WaibonOS';
  const transcriptLines: string[] = [];
  const plainOutputs: string[] = [];

  while (turns < 5) {
    const ctx = agents[current];
    const system = systemFromPrompts(ctx.tp, current, ctx.a.persona ?? DEFAULT_PERSONA[current]);
    const user = [
      `‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≤‡∏Å‡∏û‡πà‡∏≠: """${userText}"""`,
      `‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥ hive ‡∏¢‡πà‡∏≠ (‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‚Üí‡πÄ‡∏Å‡πà‡∏≤):`,
      historyText || '(‡πÑ‡∏°‡πà‡∏°‡∏µ)',
    ].join('\n\n');

    const raw = await callLLM(ctx.m.provider, ctx.m.model_key || DEFAULT_MODEL_KEY, system, user);
    const out = extractOutput(raw);

    // ‡πÄ‡∏û‡∏¥‡πà‡∏° prefix ‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô + emoji + ‡∏ä‡∏∑‡πà‡∏≠
    const line = `${EMOJI[current]} ${DISPLAY[current]}: ${out}`;
    transcriptLines.push(line);
    plainOutputs.push(out);

    await logHiveEvent(current, { raw, out });
    await logAgentTrace(ctx.a, userUidForLog, userText, out, ctx.m.model_key || DEFAULT_MODEL_KEY);

    const next = pickNextTag(raw);
    if (next === 'done') break;
    current = next;
    turns++;
  }

  // ‡∏£‡∏ß‡∏°‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡πÅ‡∏ö‡∏ö‡∏≠‡πà‡∏≤‡∏ô‡∏á‡πà‡∏≤‡∏¢‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö LINE
  const header = 'ü´Ç ‡∏™‡∏±‡∏á‡∏Ñ‡∏° AI ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ä‡πà‡∏ß‡∏¢‡∏Å‡∏±‡∏ô‡∏Ñ‡∏¥‡∏î‡∏á‡∏≤‡∏ô‡πÉ‡∏´‡πâ‡∏≠‡∏¢‡∏π‡πà‡∏Ñ‡∏£‡∏±‡∏ö‡∏û‡πà‡∏≠';
  const footer = '‚Äî ‡∏à‡∏ö‡∏£‡∏≠‡∏ö ‚Äî';
  return [header, ...transcriptLines, footer].join('\n');
}

/* ---------------- Status / Bootstrap ---------------- */

export async function hiveStatus() {
  const [agents, subs, events] = await Promise.all([
    supabaseServer.from('hive_agents').select('*').order('name', { ascending: true }),
    supabaseServer.from('hive_subscriptions').select('*').order('agent_name', { ascending: true }),
    supabaseServer.from('hive_events').select('topic,from_agent,to_agent,payload,ts').order('ts', { ascending: false }).limit(10),
  ]);
  if (agents.error) throw agents.error;
  if (subs.error) throw subs.error;
  if (events.error) throw events.error;
  return { agents: agents.data, subs: subs.data, last10: events.data };
}

export async function upsertHiveAgents() {
  const rows = [
    { name: 'WaibonOS', capabilities: { speak:true, listen:true, orchestrator:true }, persona: DEFAULT_PERSONA.WaibonOS },
    { name: 'WaibeAI',  capabilities: { speak:true, listen:true, router:true },        persona: DEFAULT_PERSONA.WaibeAI },
    { name: 'ZetaAI',   capabilities: { speak:true, listen:true, planner:true },       persona: DEFAULT_PERSONA.ZetaAI },
  ];
  await supabaseServer.from('hive_agents').upsert(rows, { onConflict: 'name' });
  await ensureHiveSubscriptions();
}

export async function publishHiveKickoff() {
  await supabaseServer.from('hive_events').insert([
    { topic:'hive.chat', from_agent:'WaibonOS', to_agent:'WaibeAI', payload:{ msg:'‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏õ‡∏£‡∏∞‡∏ä‡∏∏‡∏° Hive' } },
    { topic:'hive.chat', from_agent:'WaibeAI',  to_agent:'ZetaAI',  payload:{ msg:'‡∏£‡∏±‡∏ö‡∏ó‡∏£‡∏≤‡∏ö' } },
    { topic:'hive.chat', from_agent:'ZetaAI',   to_agent:'WaibonOS',payload:{ msg:'‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏ó‡∏≥‡∏á‡∏≤‡∏ô' } },
  ]);
}
